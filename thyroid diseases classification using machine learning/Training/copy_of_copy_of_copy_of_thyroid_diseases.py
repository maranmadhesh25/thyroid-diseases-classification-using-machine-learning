# -*- coding: utf-8 -*-
"""Copy of Copy of Copy of thyroid diseases

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_JYE99Lu9NXEi5_GsD7Vr3v8vDZwoH9f
"""

# importing required lib

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# checking for available
plt.style.available

# applying styles to notebook

plt.style.use('fivethirtyeight')

# reading csv data

df = pd.read_csv('/content/Thyroid_Dataset.csv')
df.head()

#checking data type

 df.info()

"""
 Types of Analysis
 1) Univariate analysis
 2) Bivariate analysis
 3) Multivariate analysis
 4) Descriptive analysis / statistics
 """

# univariate analysis - Extracting info from a single column

# checking data distribution

plt.figure(figsize=(8,6))
plt.subplot(121)
sns.distplot(df['age'])
plt.subplot(122)
sns.distplot(df['TSH'], color='r')

# creating dummy dataframe for categorical values

df_cat = df.select_dtypes(include='float64')
df_cat.head()

for i,j in enumerate(df_cat):
  print(j)
  print(i)

# visualizing counts in each variable
plt.figure(figsize=(18,4))
for i,j in enumerate(df_cat):
  plt.subplot(1,5,i+1)
  sns.countplot(df[j])

# Bivariate analysis - Extracting info from double column

# Visualizing the relation between TSH,T3,TT4,T4U & FIT

plt.figure(figsize=(12,5))
plt.figure(figsize=(4,5))
plt.subplot(131)
sns.countplot(df['TSH'],x=df['T3'])
plt.subplot(132)
sns.countplot(df['TSH'],x=df['TT4'])
plt.subplot(133)
sns.countplot(df['TSH'],x=df['T4U'])

df['T3'].max()

# creating new column

df['T3'] =['0.0-2'if x<=2 else "2-10" if x>2 and x<=10 else '10+' for x in df['T3']]

df.head()

# finding relation between age_ & pregnant

pd.crosstab(df['age'],df['pregnant'])

# Removing age_column

df.drop('age', axis=1, inplace=True)
df.head()

# multivariate analysis - extract info form more than 2 columns

sns.swarmplot(data=df,x='TSH', y='pregnant',hue='TT4')

# finding corr

sns.heatmap(df.corr())

# descriptive analysis - descriptive stat

df.describe(include='all')

# data preprocessing

# finding the shape of data

df.shape

# finding null values

df.isnull().sum()

print(df['sex'].mean())

print(df['sex'].mean())
df['sex'] = df['sex'].fillna(0.38229056203605516)
print(df.isnull().sum())

# finding dtype

df.info()

# finding outliers

sns.boxplot(df['TT4'])

# finding the count of oultiers

# IQR = q3-q1....., ub = q3+(1.5*IQR),lb = q1-(1.5*IQR)

q1 = np.quantile(df['TT4'],0.25)
q3 = np.quantile(df['TT4'],0.75)

print('Q1 ={}'.format(q1))
print('Q3 ={}'.format(q3))

IQR = q3-q1

print('IQR value is {}'.format(IQR))

upperBound = q3+(1.5*IQR)
lowerBound = q1-(1.5*IQR)

print('the upper bound value is {} & the lower bound value is {}'.format(upperBound,lowerBound))


print('Skwed data :',len(df[df['TT4']>upperBound]))

# Handling outliers

from scipy import stats

plt.figure(figsize=(10,4))
plt.subplot(131)
sns.distplot(df['TT4'])
plt.subplot(132)
stats.probplot(np.log(df['TT4']),plot=plt)
plt.subplot(133)
sns.distplot(df['TT4'])

stats.probplot(np.log(df['TT4']),plot=plt)

# transforming normal values to log values

df['TT4']=np.log(df['TT4'])

df.head()

# encoding 

# encoding with list comp

df['pregnant'] = [0 if x=='NORMAL'else 2 for x in df['pregnant']]

# encoding with replace method

df['sex'] = df['sex'].replace({'F':0,'M':1})

df.referral_source.unique

df['on_thyroxine'] = df['on_thyroxine'].replace({'f':0,'t':1})
df['query_on_thyroxine'] = df['query_on_thyroxine'].replace({'f':0,'t':1})
df['on_antithyroid_medication'] = df['on_antithyroid_medication'].replace({'f':0,'t':1})

df['pregnant'] = df['pregnant'].replace({'f':0,'t':1})
df['sick'] = df['sick'].replace({'f':0,'t':1})
df['thyroid_surgery'] = df['thyroid_surgery'].replace({'f':0,'t':1})
df['I131_treatment'] = df['I131_treatment'].replace({'f':0,'t':1})
df['query_hypothyroid'] = df['query_hypothyroid'].replace({'f':0,'t':1})
df['query_hyperthyroid'] = df['query_hyperthyroid'].replace({'f':0,'t':1})
df['lithium'] = df['lithium'].replace({'f':0,'t':1})
df['goitre'] = df['goitre'].replace({'f':0,'t':1})
df['tumor'] = df['tumor'].replace({'f':0,'t':1})
df['hypopituitary'] = df['hypopituitary'].replace({'f':0,'t':1})
df['psych'] = df['psych'].replace({'f':0,'t' :1})
df['TSH'] = df['TSH'].replace({'f':0,'t':1})
df['T3'] = df['T3'].replace({'f':0,'t':1})
df['TT4'] = df['TT4'].replace({'f':0,'t':1})
df['T4U'] = df['T4U'].replace({'f':0,'t':1})
df['FTI'] = df['FTI'].replace({'f':0,'t':1})
df['referral_source'] = df['referral_source'].replace({'SVHC':0,'other':1, 'SVI':2,'STMW':3,'SVHD':4})
df['Sex'] = df['sex'].replace({'F':0,'M':1})

df.head()

df.info()

# encoding with replace method

df['pregnant'] = df['pregnant'].replace({'NORMAL':0,'HIGH':1})

df.head()

# spliting dep & indep variables

x=df.drop('TT4',axis=1)
x.head()

y = df['thyroid_surgery']
y



"""#simple linear regression

"""

from sklearn.preprocessing import LabelEncoder
lc = LabelEncoder()
df['sex']= lc.fit_transform(df['sex'])

plt.scatter(df['TSH'],df['TT4'])

df.isnull().sum()

print(df['sex'].mean())

print(df['sex'].mean())
df['sex'] = df['sex'].fillna(0.3822)
print(df.isnull().sum())

"""DATA PREPARATION


"""

#independent & dependent

x = df.iloc[: , 0:1]
x.head()

y = df.iloc[:,2:]
y.head()

# split training & testing

from sklearn.model_selection import train_test_split

xtrain, xtest, ytrain, ytest = train_test_split(x,y,test_size=0.2,random_state=11)

print(xtrain.shape)
print(xtest.shape)

# Modelbuilding

from sklearn.linear_model import LinearRegression

lr = LinearRegression()

lr.fit(xtrain,ytrain)

ypred = lr.predict(xtest)

from sklearn.metrics import r2_score

r2_score(ytest,ypred)

lr.predict(py.transform([[0.00106]]))

"""#Multi linear reg"""

df.describe()

#Checking unique values

df['referral_source'].unique()

#Converting object datatype

df.head()

#independent variable
x = df.iloc[:,0:4]
x.head()

# dependent


y = df.iloc[:,4:]
y.head()

# spliting data into training & testing set

from sklearn.model_selection import train_test_split

#spelitting in to training data and test data

from  sklearn.model_selection import train_test_split
x_train , x_test , y_train , y_test = train_test_split(x , y , test_size = 0.25, random_state = 42)

print(x_train.shape)
print(x_test.shape)

#Model building 

from sklearn.linear_model import LinearRegression

lr = LinearRegression()

lr.fit(x_train,y_train)

y_pred = lr.predict(x_test)

#finding accuracy

from sklearn.metrics import r2_score

r2_score(y_test,y_pred)



"""#Polynominal Regression"""

from sklearn.preprocessing import PolynomialFeatures #polynomial regression
from sklearn.linear_model import LinearRegression  #for nbuilding the model
from sklearn.metrics import r2_score #checking accuracy

df.isnull().sum()

#finding co-relation

df.corr()

#spliting in-dependent variable

x = df.iloc[ :,0:1]
x.head()

# spliting dependent variable

y = df.iloc[:,2:3]
y.head()

#scatting plot

plt.scatter(df['age'],df['FTI'])

#initializing polynomial regression /features

py = PolynomialFeatures()

#tranfoming  x values

xp = py.fit_transform(x)
xp

#initialing linear reg

lr = LinearRegression()

#traning the model

lr.fit(xp,y)

lr.predict(py.transform([[5]]))

plt.scatter
plt.plot(x,lr.predict(py.transform(x)),'y')

from sklearn.preprocessing import PolynomialFeatures

poly = PolynomialFeatures(degree =99)
x_ploy = poly.fit_transform(x)

x_ploy

lr.fit(x_ploy,y)

plt.scatter(x ,y , color ='red')
plt.plot(x, lr.predict(poly.fit_transform(x)), color ='green')
plt.title('polynomial Regression')
plt.xlabel('sex')
plt.ylabel('TT4')
plt.show()

"""#Logistic Regression"""

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.linear_model import LinearRegression

df['on_thyroxine'] = df['on_thyroxine'].replace({'f':0,'t':1})
df['query_on_thyroxine'] = df['query_on_thyroxine'].replace({'f':0,'t':1})
df['on_antithyroid_medication'] = df['on_antithyroid_medication'].replace({'f':0,'t':1})

df['pregnant'] = df['pregnant'].replace({'f':0,'t':1})
df['sick'] = df['sick'].replace({'f':0,'t':1})
df['thyroid_surgery'] = df['thyroid_surgery'].replace({'f':0,'t':1})
df['I131_treatment'] = df['I131_treatment'].replace({'f':0,'t':1})
df['query_hypothyroid'] = df['query_hypothyroid'].replace({'f':0,'t':1})
df['query_hyperthyroid'] = df['query_hyperthyroid'].replace({'f':0,'t':1})
df['lithium'] = df['lithium'].replace({'f':0,'t':1})
df['goitre'] = df['goitre'].replace({'f':0,'t':1})
df['tumor'] = df['tumor'].replace({'f':0,'t':1})
df['hypopituitary'] = df['hypopituitary'].replace({'f':0,'t':1})
df['psych'] = df['psych'].replace({'f':0,'t' :1})
df['TSH'] = df['TSH'].replace({'f':0,'t':1})
df['T3'] = df['T3'].replace({'f':0,'t':1})
df['TT4'] = df['TT4'].replace({'f':0,'t':1})
df['T4U'] = df['T4U'].replace({'f':0,'t':1})
df['FTI'] = df['FTI'].replace({'f':0,'t':1})
df['referral_source'] = df['referral_source'].replace({'SVHC':0,'other':1, 'SVI':2,'STMW':3,'SVHD':4})

df

x = df.drop('TSH',axis=1)
y = df['TSH']

X_train

Y

#spliting training data & testing data

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state = 40)

#Initialing logstic reg

log_r = LogisticRegression()

df.isnull().sum()

log_r.fit(x_train,y_train)

y_test = log_r.predict(x_test)

y_test

#Evaluating model

from sklearn.metrics import classification_report, confusion_matrix

x_train.shape,y_train.shape

x_test.shape,y_test.shape

print(classification_report(y_test,dt.predict(x_test)))

confusion_matrix(y_test,dt.predict(x_test))

log_r.predict(py.transform(Male,0.7,187))



"""#Decision tree """

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix
from scipy import stats
from sklearn.tree import DecisionTreeClassifier

df.info()

sns.boxplot(df['TT4'])

#finding the count of outiler 
#IQR=q3-q1......, ub = q3+(1.5*IQR), lb = q1-(1.5*IQR)

q1 = np.quantile(df['TT4'],0.25)

q3 = np.quantile(df['TT4'],0.75)

print('Q1 = {}'.format(q1))
print('Q3 = {}'.format(q3))

IQR = q3-q1

print('IQR value is {}'.format(IQR))

upperbound = q3+(1.5*IQR)
lowerbound = q1-(1.5*IQR)

print('Skwed data :',len(df[df['TT4']>upperbound]))

print('The upper bound is {} & the lower bound  value is {}'.format(upperbound,lowerbound))

#handling outliers

def transform(variable):
  plt.figure(figsize=(14,6))
  plt.subplot(121)
  sns.displot("variable")
  plt.subplot(122)
  stats.probplot(variable,plot=plt)

transform(df['TT4'])

df['pregnant'] = np.log(df['pregnant'])
df.head()

x = df.drop('referral_source',axis=1)
y = df['referral_source']

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=25)

x_train

x_train.shape,x_test.shape

y_train.shape,y_test.shape

#Decision tree

dt = DecisionTreeClassifier()

dt.fit(x_train,y_train)

y_test

pd.Series(dt.predict(x_test))

pd.DataFrame([y_test,dt.predict(x_test)])

pd.DataFrame([y_test,dt.predict(x_test)],columns=['Actual','predict'])

pd.DataFrame([y_test,dt.predict(x_test)],colunmns=(['Actual_value','predict_value']))

pd.DataFrame([y_test,pd.Series(dt.predict(x_test))],columns=['Atual','Predict'])

print(classification_report(y_test,dt.predict(x_test)))

confusion_matrix(y_test,dt.predict(x_test))



"""#Random forest"""

!pip install cartopy
import cartopy

precision recall f1 score support

dt.predict(x_test)

pd.DataFrame(np.array(y_test),dt.predict(x_test))

a = pd.DataFrame(np.array(y_test),dt.predict(x_test)).T

a.colunmns=(['Actual_value','predict_value'])

a.colunmns=['Actual_value','predict_value']

a

# random froest

rf=RandomForestClassifier()

rf.fit(x_train,y_train)

print(classification_report(y_test,rf.predict(x_test)))

confusion_matrix(y_test,dt.predict(x_test))

dt.predict(x_test)

rf.predict([[65,1,0.7,187,16,100,7,3.3,0.9,np.log(25)]])

rf.predict([[75,1,1,208,53,60,7,3.4,0.9,np.log(15)]])



"""# KNN"""

from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier()

knn.fit(x_train,y_train)

print(classification_report(y_test,knn.predict(x_test)))

confusion_matrix(y_test,knn.predict(x_test))

print(classification_report(y_test,knn.predict(x_test)))



"""#SVM

"""

from sklearn.svm import SVC

svc = SVC()

svc.fit(x_train,y_train)

print(classification_report(y_test,svc.predict(x_test)))

confusion_matrix(y_test,svc.predict(x_test))

svc1 = SVC(kernel='linear')

svc1.fit(x_train,y_train)

print(classification_report(y_test,svc1.predict(x_test)))

confusion_matrix(y_test,svc1.predict(x_test))



"""#Navie bayes"""

from sklearn import naive_bayes
import pandas as pd
import numpy as np

data = pd.read_csv('/content/Thyroid_Dataset.csv')
data.head()

data.shape

data.isnull().sum()

#spliting denpendent &independent 

x = data.iloc[:,1:]
y = data.iloc[:,0]

y

col_name = x.columns

x.columns

#manual encoding

x = np.where(x=='y',1,x)
x = np.where(x=='n',0,x)
x = np.where(x=='?',1,x)

x = pd.DataFrame(x,columns=col_name)
x.head()

df['on_thyroxine'] = df['on_thyroxine'].replace({'f':0,'t':1})
df['query_on_thyroxine'] = df['query_on_thyroxine'].replace({'f':0,'t':1})
df['on_antithyroid_medication'] = df['on_antithyroid_medication'].replace({'f':0,'t':1})

df['pregnant'] = df['pregnant'].replace({'f':0,'t':1})
df['sick'] = df['sick'].replace({'f':0,'t':1})
df['thyroid_surgery'] = df['thyroid_surgery'].replace({'f':0,'t':1})
df['I131_treatment'] = df['I131_treatment'].replace({'f':0,'t':1})
df['query_hypothyroid'] = df['query_hypothyroid'].replace({'f':0,'t':1})
df['query_hyperthyroid'] = df['query_hyperthyroid'].replace({'f':0,'t':1})
df['lithium'] = df['lithium'].replace({'f':0,'t':1})
df['goitre'] = df['goitre'].replace({'f':0,'t':1})
df['tumor'] = df['tumor'].replace({'f':0,'t':1})
df['hypopituitary'] = df['hypopituitary'].replace({'f':0,'t':1})
df['psych'] = df['psych'].replace({'f':0,'t' :1})
df['TSH'] = df['TSH'].replace({'f':0,'t':1})
df['T3'] = df['T3'].replace({'f':0,'t':1})
df['TT4'] = df['TT4'].replace({'f':0,'t':1})
df['T4U'] = df['T4U'].replace({'f':0,'t':1})
df['FTI'] = df['FTI'].replace({'f':0,'t':1})
df['referral_source'] = df['referral_source'].replace({'SVHC':0,'other':1, 'SVI':2,'STMW':3,'SVHD':4})
df['Sex'] = df['sex'].replace({'F':0,'M':1})

x.head()

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=0)

x_train.shape,y_train.shape

nb = naive_bayes.GaussianNB()

nb.fit(x_train,y_train)

print(classification_report(y_test,nb.predict(x_test)))

confusion_matrix(y_test,nb.predict(x_test))



"""#ANN Regression"""

#converting object dtype into int dtype

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

df.head()

# independent variable 

x = df.drop('Albumin',axis=1)
x.head()

#dependent

y = df.iloc[:,9:]
y.head()

#spliting traing and tetting data

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=10)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential() #Initializing the model
model.add(Dense(10,activation='relu')) #Input layer
model.add(Dense(30, activation='relu')) #Hideen layer
model.add(Dense(1, activation='linear'))  # Output layer

model.compile(optimizer='rmsprop',loss='mse', metrics=['mse'])

model.fit(x_train, y_train, batch_size=2, epochs=20)

model.predict([[50,1,10.9,5.5,290,64,100.7,7.5,1.0,1]])



"""#ANN Classification"""

data.isnull().sum()

data['TSH'] = np.log(data['TSH'])

data['sex'] = [0 if x == 'M'  else 1 for x in data['sex']]

data.head()

data.info()

x = data.drop('pregnant',axis=1)
x.head()

y = data['pregnant']
y

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=11)

classification = Sequential()
classification.add(Dense(10,activation='relu'))
classification.add(Dense(64,activation='relu'))
classification.add(Dense(5,activation='softmax'))

classification.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])

classification.fit(x_train,y_train,batch_size=2,epochs=30,validation_data=(x_test,y_test))

classification.predict([[58,1,18,1.65,16,18,6.8,3.3,0.9,1]])

np.argmax(classification.predict([[58,1,18,1.65,16,18,6.8,3.3,0.9,1]]))

op = np.argmax(classification.predict([[58,1,18,1.65,16,18,6.8,3.3,0.9,1]]))

op

x

